import pandas as pd
import jieba
import re
from collections import Counter
import os

# ---------------------- 1. æ ¸å¿ƒé…ç½®ï¼ˆå…¨é‡å‰”é™¤è¿è¯+æ–°å¢æ— å…³è¯ï¼‰ ----------------------
DESKTOP = os.path.join(os.path.expanduser("~"), "Desktop")  # æ¡Œé¢è·¯å¾„
FILE_PATHS = {
    "èµµä¸½é¢–": os.path.join(DESKTOP, "èµµä¸½é¢–è¯„è®ºçˆ¬å–.xlsx"),
    "æ´›å¤©ä¾": os.path.join(DESKTOP, "æ´›å¤©ä¾è¯„è®ºçˆ¬å–.xlsx")
}
OUTPUT_PATH = os.path.join(DESKTOP, "åŒå¶åƒé«˜é¢‘è¯_æ— è¿è¯çº¯å‡€ç‰ˆ.xlsx")  # è¾“å‡ºæ–‡ä»¶

# ã€å¿…é¡»ä¿ç•™ã€‘çš„è¯ï¼šä»…å¶åƒæ˜µç§°ï¼ˆæ— å…¶ä»–å†—ä½™ï¼‰
RESERVED_NICKNAMES = {
    "èµµä¸½é¢–": {"èµµå§", "é¢–å®", "ä¸½é¢–"},
    "æ´›å¤©ä¾": {"å¤©ä¾", "æ®¿ä¸‹"}
}

# ã€å½»åº•å‰”é™¤ã€‘çš„è¯ï¼ˆæ–°å¢ç›®æ ‡è¯+å…¨é‡è¿è¯+æ— å…³è¯ï¼‰
ALL_STOP_WORDS = {
    # ä½ æœ€æ–°æŒ‡å®šçš„è¯
    "è¿™éƒ¨", "å‰§é‡Œ", "æ˜¯å› ä¸º", "å¦‚æœ", "å°å­¦", "å‘ç°", "è€Œæ˜¯",
    # ä¹‹å‰æ‰€æœ‰æŒ‡å®šçš„åœç”¨è¯ï¼ˆå®Œæ•´ä¿ç•™ï¼‰
    "å› ä¸º", "è€Œä¸”", "åæ¥", "ç”šè‡³", "çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "ä½ ", "ä»–", "è¿™ä¸ª", "é‚£ä¸ª", "å›å¤", "çœŸçš„",
    "è§‰å¾—", "å°±æ˜¯", "è¿™æ ·", "ä»€ä¹ˆ", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "æ²¡æœ‰", "ä¸æ˜¯", "è¿˜æœ‰", "å…¶å®", "å‘¢", "å§", "å—", "å•Š",
    "å‘€", "å“¦", "å‘ƒ", "å˜›", "è‡ªå·±", "ä¸€ç›´", "è¿˜æ˜¯", "è¿™ä¹ˆ", "ä¸€ä¸ª", "ç°åœ¨", "ä½†æ˜¯", "æ„Ÿè§‰", "å½“æ—¶", "æˆ‘ä»¬",
    "çœ‹åˆ°", "æ—¶å€™", "è¶Šæ¥è¶Š", "ä¹‹å‰", "å‡ºæ¥", "é£å¹", "çœ‹è¿‡", "æ‰€ä»¥", "æ ·å­", "å¥½ä¸å¥½", "ä¸€ä¸‹", "çŸ¥é“", "å¯èƒ½",
    "ä¸‹æ¬¡", "å¸Œæœ›", "å¯ä»¥", "è™½ç„¶", "è¿™ç§", "ä»¥å", "å·²ç»", "éå¸¸", "ä»Šå¤©", "ä¸€æ ·", "æˆä¸º", "å¾ˆå¤š", "é‚£ç§",
    "å¤šå¹´", "é‚£ä¹ˆ", "çœ¼ç›", "ä»¥å‰", "å¿ƒå¿ƒ", "åªæ˜¯", "çœŸæ­£", "ä¸€èµ·", "çœ‹ç€", "ç»å†", "å¥¹ä»¬", "ä¸€éƒ¨", "å®Œå…¨",
    "ç¡®å®", "æ°¸è¿œ", "æ‰€ä»¥", "å› æ­¤", "å› è€Œ", "äºæ˜¯", "æ•…è€Œ", "ä»¥è‡´", "æ—¢ç„¶", "ç”±äº", "å¹¶ä¸”", "å†µä¸”", "å†è€…",
    "æ­¤å¤–", "å¦å¤–", "åŠ ä¹‹", "ä½•å†µ", "ä¹ƒè‡³", "å¯æ˜¯", "ç„¶è€Œ", "ä¸è¿‡", "å´", "åå", "åå€’", "åè€Œ", "å°”å",
    "éšå", "ç»§è€Œ", "æ¥ç€", "ä¹‹å", "æ­¤å", "å¾€å", "å¥¹", "å®ƒ", "è¿™", "é‚£", "æ­¤", "å½¼", "å’Œ", "ä¸", "åŠ",
    "ä¹Ÿ", "éƒ½", "åª", "åˆ", "è¿˜", "æ›´", "æœ€", "å¾ˆ", "æŒº", "å¤ª", "å¯", "è€Œ", "æˆ–", "å¹¶", "ä¸”", "å•¦", "å“©",
    "å–½", "å“‰", "çŸ£", "ä¹Ÿç½¢", "ä¹Ÿå¥½", "å“å“Ÿ", "å“å‘€", "å—¨å“Ÿ", "å“‡å¡", "å“‡", "å•Šå‘€", "å“¦å“Ÿ", "å‘ƒå“Ÿ", "æ˜¨å¤©",
    "æ˜å¤©", "åå¤©", "å‰å¤©", "ä»Šå¹´", "æ˜å¹´", "å»å¹´", "å‰å¹´", "æ—¥å", "å°†æ¥", "è¿‡å»", "è¿‡å¾€", "æ›¾ç»", "å·²ç„¶",
    "å°šæœª", "å°†è¦", "æ­£åœ¨", "åˆšåˆš", "æ–¹æ‰", "ç«‹é©¬", "ç«‹åˆ»", "ä¸¤ä¸ª", "ä¸‰ä¸ª", "å‡ ä¸ª", "ä¸€äº›", "æŸäº›", "è‹¥å¹²",
    "ä¸å°‘", "è®¸å¤š", "å¤§é‡", "å°‘é‡", "ä¸ªåˆ«", "å…¨ä½“", "æ‰€æœ‰", "å…¨éƒ¨", "ä»»ä½•", "æ¯ä¸€ä¸ª", "æ¯ä¸ª", "å„è‡ª", "å¤§å®¶",
    "å¤§ä¼™", "äººä»¬", "åˆ«äºº", "ä»–äºº", "ç‰¹åˆ«", "å°¤å…¶", "æ ¼å¤–", "ååˆ†", "ç›¸å½“", "æåº¦", "æå…¶", "ç•¥å¾®", "ç¨å¾®",
    "å‡ ä¹", "å°†è¿‘", "å¤§çº¦", "çš„ç¡®", "å®åœ¨", "åŸæœ¬", "æœ¬æ¥", "åŸæ¥", "ç©¶ç«Ÿ", "åˆ°åº•", "ç»ˆç©¶", "ç»ˆå½’", "èƒ½å¤Ÿ",
    "ä¼š", "èƒ½", "æ„¿", "æ„¿æ„", "æƒ³è¦", "è¦", "æ‰“ç®—", "è®¡åˆ’", "å‡†å¤‡", "åº”è¯¥", "åº”å½“", "è¯¥", "éœ€", "éœ€è¦",
    "å¿…é¡»", "å¾—", "è¦å¾—", "ä¸ç”¨", "ä¸å¿…", "æ— éœ€", "æœªå°", "ä¸å¦¨", "è¿™äº›", "é‚£äº›", "è¿™è¾¹", "é‚£è¾¹", "è¿™é‡Œ",
    "é‚£é‡Œ", "è¿™ç‚¹", "é‚£ç‚¹", "è¿™èˆ¬", "é‚£èˆ¬", "è¿™ä¹ˆæ ·", "é‚£ä¹ˆæ ·", "å¦‚æ­¤", "æŸä¸€", "æŸç±»", "æŸæ ·", "æŸç§",
    "æœ›ç€", "å¬ç€", "è¯´ç€", "æƒ³ç€", "åšç€", "èµ°ç€", "è·‘ç€", "è·³ç€", "æ´»ç€", "ç»è¿‡", "åº¦è¿‡", "æ¸¡è¿‡", "é­é‡",
    "é‡åˆ°", "ç¢°åˆ°", "æ’è§", "å¬è§", "é—»åˆ°", "è¿›å»", "ä¸Šæ¥", "ä¸‹å»", "è¿›æ¥", "å‡ºå»", "èµ·æ¥", "è¿‡æ¥", "è¿‡å»",
    "å›æ¥", "å›å»", "å¿ƒæ€", "å¿ƒæƒ…", "å¿ƒç»ª", "å¿ƒæ„", "ä¸€æœ¬", "ä¸€å¼ ", "ä¸€ç‰‡", "ä¸€å—", "ä¸€ä»¶", "ä¸€åŒ", "ä¸€å¯¹",
    "ä¸€ç¾¤", "ä¸€å †", "ä¸€é˜µ", "ä¸€åœº", "ä¸€æ¬¡", "ä¸€å›", "ä¸€è¶Ÿ", "ä¸€ä¸‹ä¸‹", "è€³æœµ", "é¼»å­", "å˜´å·´", "å¤´å‘", "çš®è‚¤",
    "æ‰‹è„š", "èº«ä½“", "å››è‚¢", "äº”å®˜", "å†…è„", "åªä¸è¿‡", "ä»…ä»…", "å•å•", "çº¯ç²¹", "å•çº¯", "ç®€ç›´", "æ ¹æœ¬", "å½»åº•",
    "å…¨ç„¶", "ç»Ÿç»Ÿ", "æ°¸ä¹…", "æ°¸æ’", "é•¿ä¹…", "é•¿è¿œ", "çŸ­æœŸ", "æš‚æ—¶", "ä¸´æ—¶", "æš‚ä¸”",
    # ã€å…¨é‡è¿è¯è¡¥å……ã€‘ï¼ˆå› æœ/å‡è®¾/è½¬æŠ˜/å¹¶åˆ—/æ¡ä»¶ç­‰ï¼Œä¸€ä¸ªä¸ç•™ï¼‰
    # å‡è®¾è¿è¯
    "å¦‚æœ", "å‡å¦‚", "å‡è‹¥", "å‡ä½¿", "å€˜è‹¥", "å€˜ä½¿", "è¦æ˜¯", "è‹¥æ˜¯", "ä¸‡ä¸€", "è‹¥", "å³ä½¿", "å³ä¾¿", "å“ªæ€•", "çºµç„¶",
    # å› æœè¿è¯ï¼ˆå«â€œæ˜¯å› ä¸ºâ€ï¼‰
    "å› ä¸º", "ç”±äº", "æ˜¯å› ä¸º", "æ‰€ä»¥", "å› æ­¤", "å› è€Œ", "äºæ˜¯", "æ•…è€Œ", "ä»¥è‡´", "æ—¢ç„¶", "æ‰€ä»¥è¯´", "ä¹‹æ‰€ä»¥",
    # è½¬æŠ˜è¿è¯ï¼ˆå«â€œè€Œæ˜¯â€ï¼‰
    "ä½†æ˜¯", "å¯æ˜¯", "ç„¶è€Œ", "ä¸è¿‡", "å´", "åªæ˜¯", "åå", "åå€’", "åè€Œ", "è€Œæ˜¯", "ä¸æ–™", "è°çŸ¥", "å“ªæ›¾æƒ³",
    # å¹¶åˆ—è¿è¯
    "å’Œ", "ä¸", "åŠ", "ä»¥åŠ", "å¹¶", "å¹¶ä¸”", "è€Œ", "åˆ", "ä¹Ÿ", "è¿˜", "åŒæ—¶", "å¦å¤–", "æ­¤å¤–", "åŠ ä¹‹", "å†µä¸”",
    # æ¡ä»¶è¿è¯
    "åªè¦", "åªæœ‰", "é™¤é", "æ— è®º", "ä¸è®º", "ä¸ç®¡", "ä»»å‡­", "åªè¦æ˜¯", "é™¤éæ˜¯",
    # é€‰æ‹©è¿è¯
    "æˆ–è€…", "æˆ–æ˜¯", "è¦ä¹ˆ", "ä¸æ˜¯...å°±æ˜¯", "å®å¯", "å®æ„¿", "ä¸å…¶", "ä¸å¦‚",
    # ã€æ–°å¢æ— å…³è¯ã€‘ï¼ˆå’Œâ€œè¿™éƒ¨ã€å‰§é‡Œã€å°å­¦â€åŒç±»ï¼Œæ— è¯„ä»·æ„ä¹‰ï¼‰
    "è¿™éƒ¨", "é‚£éƒ¨", "è¿™éƒ¨å‰§", "é‚£éƒ¨å‰§", "å‰§é‡Œ", "å‰§ä¸­", "æˆé‡Œ", "æˆä¸­", "å°å­¦", "ä¸­å­¦", "å¤§å­¦", "å­¦æ ¡", "å¹´çº§",
    "ç­çº§", "å‘ç°", "æ‰¾åˆ°", "çœ‹è§", "å¬è§", "é—»åˆ°", "æ‘¸åˆ°", "æŸ¥åˆ°", "æƒ³åˆ°", "çŒœåˆ°", "æ–™åˆ°", "è§‰åˆ°"
}

# ---------------------- 2. æ ¸å¿ƒé€»è¾‘ï¼šæ— è¿è¯+æ— æ— å…³è¯ï¼Œåªç•™â€œè¯„ä»·è¯+æ˜µç§°â€ ----------------------
def extract_no_conjunction_words(excel_path, idol_name):
    """
    ç»ˆæè¿‡æ»¤é€»è¾‘ï¼š
    1. å‰”é™¤æ‰€æœ‰è¿è¯ï¼ˆå› æœ/å‡è®¾/è½¬æŠ˜ç­‰ï¼Œä¸€ä¸ªä¸ç•™ï¼‰
    2. å‰”é™¤â€œè¿™éƒ¨ã€å‰§é‡Œâ€ç­‰æ— å…³è¯
    3. åªç•™â€œé•¿åº¦â‰¥2çš„è¯„ä»·è¯â€å’Œâ€œå¶åƒæ˜µç§°â€
    """
    # è¯»å–Excelå¹¶åŒ¹é…è¯„è®ºåˆ—
    df = pd.read_excel(excel_path)
    comment_cols = ["è¯„è®ºå†…å®¹", "è¯„è®º", "ç”¨æˆ·è¯„è®º", "ç²‰ä¸è¯„è®º", "content"]
    comment_col = next((col for col in comment_cols if col in df.columns), None)
    if not comment_col:
        raise ValueError(f"{idol_name}çš„Excelä¸­æœªæ‰¾åˆ°è¯„è®ºåˆ—ï¼ˆå¦‚â€œè¯„è®ºå†…å®¹â€ï¼‰ï¼Œè¯·æ£€æŸ¥åˆ—åï¼")
    
    # æå–éç©ºè¯„è®º
    comments = df[comment_col].dropna().astype(str).tolist()
    all_pure_words = []
    idol_nicks = RESERVED_NICKNAMES[idol_name]
    
    for comment in comments:
        # æ­¥éª¤1ï¼šæ·±åº¦æ¸…æ´—ï¼Œä»…ä¿ç•™ä¸­æ–‡ï¼ˆå‰”é™¤ç¬¦å·ã€æ•°å­—ã€è‹±æ–‡ï¼‰
        pure_chinese = re.sub(r"[^\u4e00-\u9fa5]", "", comment)
        # æ­¥éª¤2ï¼šç²¾å‡†åˆ†è¯ï¼ˆé¿å…æ˜µç§°è¢«åˆ‡åˆ†ï¼Œå¦‚â€œé¢–å®â€ä¸æ‹†ä¸ºâ€œé¢–â€â€œå®â€ï¼‰
        words = jieba.lcut(pure_chinese, cut_all=False)
        
        # æ­¥éª¤3ï¼šæ— è¿è¯è¿‡æ»¤ï¼Œåªç•™ç›®æ ‡è¯
        for word in words:
            # ä¿ç•™æ¡ä»¶ï¼šé•¿åº¦â‰¥2 + ä¸æ˜¯åœç”¨è¯ï¼ˆæ— è¿è¯+æ— æ— å…³è¯ï¼‰ + ä¸æ˜¯å¶åƒå…¨å
            if len(word) >= 2 and word not in ALL_STOP_WORDS and idol_name not in word:
                all_pure_words.append(word)
    
    # å®¹é”™ï¼šæ— æœ‰æ•ˆè¯æ—¶æç¤º
    if not all_pure_words:
        raise ValueError(f"{idol_name}çš„è¯„è®ºä¸­æœªæå–åˆ°æœ‰æ•ˆè¯ï¼ˆå¯èƒ½å…¨æ˜¯è¿è¯/æ— å…³è¯ï¼‰ï¼")
    
    # ç»Ÿè®¡é«˜é¢‘è¯å¹¶æ•´ç†æ ¼å¼
    word_counter = Counter(all_pure_words)
    pure_df = pd.DataFrame(
        word_counter.items(),
        columns=["æ— è¿è¯çº¯å‡€è¯ï¼ˆè¯„ä»·è¯+æ˜µç§°ï¼‰", "å‡ºç°æ¬¡æ•°"]
    ).sort_values("å‡ºç°æ¬¡æ•°", ascending=False).reset_index(drop=True)
    
    # è¡¥å……å®ç”¨åˆ—ï¼šè¯é¢‘å æ¯”ã€æ‰€å±å¶åƒã€æ˜¯å¦ä¸ºæ˜µç§°
    total_count = pure_df["å‡ºç°æ¬¡æ•°"].sum()
    pure_df["è¯é¢‘å æ¯”(%)"] = round((pure_df["å‡ºç°æ¬¡æ•°"] / total_count) * 100, 3)
    pure_df["æ‰€å±å¶åƒ"] = idol_name
    pure_df["æ˜¯å¦ä¸ºå¶åƒæ˜µç§°"] = pure_df["æ— è¿è¯çº¯å‡€è¯ï¼ˆè¯„ä»·è¯+æ˜µç§°ï¼‰"].apply(
        lambda x: "æ˜¯" if x in idol_nicks else "å¦"
    )
    
    print(f"âœ… {idol_name}å¤„ç†å®Œæˆï¼šå…±{len(pure_df)}ä¸ªæ— è¿è¯çº¯å‡€è¯ï¼ˆæ— ä»»ä½•å†—ä½™ï¼‰")
    return pure_df

# ---------------------- 3. æ‰§è¡Œç”Ÿæˆï¼šè¾“å‡ºæ— è¿è¯çº¯å‡€ç‰ˆExcel ----------------------
if __name__ == "__main__":
    print("ğŸ”´ å¼€å§‹ç”Ÿæˆã€æ— è¿è¯çº¯å‡€ç‰ˆã€‘é«˜é¢‘è¯Excelï¼ˆæ— è¿è¯+æ— æ— å…³è¯ï¼Œä»…å«è¯„ä»·è¯+æ˜µç§°ï¼‰")
    print(f"ğŸ’¡ å·²å…¨é‡åˆ é™¤ï¼š1. ä½ æŒ‡å®šçš„â€œè¿™éƒ¨ã€å‰§é‡Œã€æ˜¯å› ä¸ºã€å¦‚æœâ€ç­‰è¯ 2. æ‰€æœ‰è¿è¯ï¼ˆå› æœ/å‡è®¾/è½¬æŠ˜ç­‰ï¼‰")
    print("-" * 80)
    
    pure_dfs = []  # å­˜å‚¨ä¸¤ä¸ªå¶åƒçš„çº¯å‡€è¯æ•°æ®
    
    # å¾ªç¯å¤„ç†èµµä¸½é¢–ã€æ´›å¤©ä¾çš„è¯„è®ºæ–‡ä»¶
    for idol_name, excel_path in FILE_PATHS.items():
        print(f"\nğŸ” æ­£åœ¨å¤„ç†{idol_name}çš„è¯„è®ºæ–‡ä»¶...")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(excel_path):
            print(f"âŒ æœªæ‰¾åˆ°{idol_name}çš„æ–‡ä»¶ï¼š{os.path.basename(excel_path)}")
            print(f"   è¯·ç¡®è®¤ï¼š1. æ–‡ä»¶åœ¨æ¡Œé¢ 2. æ–‡ä»¶åä¸é…ç½®å®Œå…¨ä¸€è‡´ï¼ˆå¦‚â€œèµµä¸½é¢–è¯„è®ºçˆ¬å–.xlsxâ€ï¼‰")
            continue
        
        # æå–æ— è¿è¯çº¯å‡€è¯ï¼ˆæ•è·æ‰€æœ‰å¯èƒ½é”™è¯¯ï¼‰
        try:
            idol_pure_df = extract_no_conjunction_words(excel_path, idol_name)
            pure_dfs.append(idol_pure_df)
        except ValueError as ve:
            print(f"âŒ {idol_name}å¤„ç†å¤±è´¥ï¼š{str(ve)}")
            continue
        except Exception as e:
            print(f"âŒ {idol_name}å¤„ç†å¼‚å¸¸ï¼š{str(e)}ï¼ˆå»ºè®®å°†Excelå¦å­˜ä¸º.xlsxæ ¼å¼åé‡è¯•ï¼‰")
            continue
    
    # åˆå¹¶æ•°æ®å¹¶ä¿å­˜Excelï¼ˆä»…å½“æœ‰æœ‰æ•ˆæ•°æ®æ—¶ï¼‰
    if pure_dfs:
        final_pure_df = pd.concat(pure_dfs, ignore_index=True)
        final_pure_df.to_excel(OUTPUT_PATH, index=False, engine="openpyxl")
        
        # è¾“å‡ºç»“æœæ€»ç»“
        print(f"\n" + "=" * 80)
        print("ğŸ‰ ã€æ— è¿è¯çº¯å‡€ç‰ˆã€‘é«˜é¢‘è¯Excelç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“ ä¿å­˜è·¯å¾„ï¼šæ¡Œé¢/{os.path.basename(OUTPUT_PATH)}")
        print(f"\nğŸ“Š Excelæ ¸å¿ƒç‰¹ç‚¹ï¼ˆæ— éœ€å†æ‰‹åŠ¨åˆ è¯ï¼‰ï¼š")
        print(f"   1. æ— ä»»ä½•è¿è¯ï¼šå› æœï¼ˆå› ä¸º/æ‰€ä»¥ï¼‰ã€å‡è®¾ï¼ˆå¦‚æœ/å‡å¦‚ï¼‰ã€è½¬æŠ˜ï¼ˆä½†æ˜¯/è€Œæ˜¯ï¼‰ç­‰å…¨åˆ ï¼›")
        print(f"   2. æ— æ— å…³è¯ï¼šâ€œè¿™éƒ¨ã€å‰§é‡Œã€å°å­¦ã€å‘ç°â€ç­‰æ— è¯„ä»·æ„ä¹‰çš„è¯å…¨åˆ ï¼›")
        print(f"   3. ä»…ç•™ä¸¤ç±»è¯ï¼šå¶åƒæ˜µç§°ï¼ˆèµµå§/é¢–å®/å¤©ä¾/æ®¿ä¸‹ï¼‰+ æœ‰æ•ˆè¯„ä»·è¯ï¼ˆå¯çˆ±/ä¼˜ç§€/å¥½å¬ç­‰ï¼‰ï¼›")
        print(f"   4. ç›´æ¥ç”¨ï¼šå¤åˆ¶â€œæ— è¿è¯çº¯å‡€è¯â€åˆ—åˆ°è¯äº‘å·¥å…·ï¼Œä¸€æ­¥ç”Ÿæˆé«˜è´¨é‡è¯äº‘ã€‚")
        
        # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®ï¼ˆå„å¶åƒå‰3æ¡çº¯å‡€è¯ï¼‰
        print(f"\nğŸŒŸ çº¯å‡€è¯ç¤ºä¾‹ï¼ˆå‰3æ¡ï¼‰ï¼š")
        for idol_name in ["èµµä¸½é¢–", "æ´›å¤©ä¾"]:
            idol_sample = final_pure_df[final_pure_df["æ‰€å±å¶åƒ"] == idol_name].head(3)
            if not idol_sample.empty:
                print(f"\n{idol_name}ï¼š")
                for _, row in idol_sample.iterrows():
                    nick_mark = "ï¼ˆå¶åƒæ˜µç§°ï¼‰" if row["æ˜¯å¦ä¸ºå¶åƒæ˜µç§°"] == "æ˜¯" else ""
                    print(f"   - {row['æ— è¿è¯çº¯å‡€è¯ï¼ˆè¯„ä»·è¯+æ˜µç§°ï¼‰']}{nick_mark}ï¼šå‡ºç°{row['å‡ºç°æ¬¡æ•°']}æ¬¡")
        print("=" * 80)
    
    else:
        print(f"\n" + "=" * 80)
        print("âŒ æœªç”ŸæˆExcelï¼è¯·ä¼˜å…ˆè§£å†³ä»¥ä¸‹é—®é¢˜ï¼š")
        print("   1. ç¡®ä¿ä¸¤ä¸ªå¶åƒçš„è¯„è®ºæ–‡ä»¶éƒ½åœ¨æ¡Œé¢ï¼Œä¸”æ–‡ä»¶åæ­£ç¡®")
        print("   2. æ‰“å¼€Excelç¡®è®¤æœ‰â€œè¯„è®ºå†…å®¹â€ç­‰è¯„è®ºåˆ—ï¼Œä¸”è¯„è®ºåŒ…å«ä¸­æ–‡è¯„ä»·")
        print("   3. è‹¥è¯„è®ºå…¨æ˜¯è¿è¯/æ— å…³è¯ï¼Œè¡¥å……å«è¯„ä»·çš„è¯„è®ºåé‡è¯•")
        print("=" * 80)
